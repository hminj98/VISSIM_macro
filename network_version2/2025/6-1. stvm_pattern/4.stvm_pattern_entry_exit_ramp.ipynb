{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-29T07:37:26.369246Z",
     "start_time": "2025-10-29T07:33:54.461189Z"
    }
   },
   "source": [
    "import gc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "ToyNetwork 재분석\n",
    "    램프 : 진입 + 진출\n",
    "    집계시간 : 5분\n",
    "    분석시간 1800~8400\n",
    "    검지기 : 842개\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "# FIX 값 모음\n",
    "###################################################################################################################\n",
    "\n",
    "path = r\"C:\\VISSIM_Workspace\\테스트\\램프0_진입+진출램프\\mer 통합\"\n",
    "\n",
    "start_interval = 1800\n",
    "end_interval = 8400\n",
    "\n",
    "weights = {\n",
    "    \"w1\" : 1,\n",
    "    \"w2\" : 1,\n",
    "    \"w3\" : 1,\n",
    "    \"w4\" : 1,\n",
    "    \"w5\" : 1,\n",
    "    \"w6\" : 1\n",
    "}\n",
    "\n",
    "vehicle_types = [100, 300, 630, 640, 650]\n",
    "\n",
    "# 램프 전 본선 검지기\n",
    "before_ramp = [49, 54]\n",
    "\n",
    "# 램프 후 본선 검지기\n",
    "after_ramp = [53, 222]\n",
    "\n",
    "# 진출 정상성(진입)\n",
    "enter_line = [54]\n",
    "\n",
    "# 유입 검지기\n",
    "input_ramp = [998]\n",
    "\n",
    "# 유출 검지기\n",
    "output_ramp = [999]\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# 함수 모음\n",
    "###################################################################################################################\n",
    "\n",
    "# 속도 변화율\n",
    "def speed_mean(original_df):\n",
    "    copy_df = original_df.copy()\n",
    "\n",
    "    # 램프 검지기 제외\n",
    "    copy_df = copy_df[~copy_df[\"New_Measurement\"].between(900, 910)]\n",
    "\n",
    "    # TimeGroup, New_Measurement별 그룹화 및 속도 평균\n",
    "    speed_mean_df = (\n",
    "        copy_df.groupby([\"TimeGroup\", \"New_Measurement\"])\n",
    "          .agg(V_mean=(\"v[km/h]\", \"mean\"), V_count=(\"v[km/h]\", \"count\"))\n",
    "          .reset_index()\n",
    "    )\n",
    "    speed_mean_df[\"V_next\"] = speed_mean_df.groupby(\"TimeGroup\")[\"V_mean\"].shift(-1)\n",
    "    speed_mean_df[\"delta_V\"] = (speed_mean_df[\"V_next\"] - speed_mean_df[\"V_mean\"]) / speed_mean_df[\"V_mean\"]\n",
    "    speed_mean_df[\"delta_V\"] = speed_mean_df[\"delta_V\"].fillna(0)\n",
    "\n",
    "    return speed_mean_df\n",
    "\n",
    "# 밀도 변화율\n",
    "def density_mean(speed_df):\n",
    "    copy_df = speed_df.copy()\n",
    "    density_mean_df = copy_df.assign(K = copy_df[\"V_count\"] * 12 / copy_df[\"V_mean\"])\n",
    "    density_mean_df[\"K_next\"] = density_mean_df.groupby(\"TimeGroup\")[\"K\"].shift(-1)\n",
    "    density_mean_df[\"delta_K\"] = (density_mean_df[\"K_next\"] - density_mean_df[\"K\"]) / density_mean_df[\"K\"]\n",
    "    density_mean_df[\"delta_K\"] = density_mean_df[\"delta_K\"].fillna(0)\n",
    "    return density_mean_df\n",
    "\n",
    "# 중차량 혼입률\n",
    "def heavy_rate(original_df):\n",
    "    copy_df = original_df.copy()\n",
    "\n",
    "    heavy_df = (\n",
    "        copy_df[copy_df[\"Vehicle type\"].isin([630, 640, 650])]\n",
    "        .groupby([\"TimeGroup\", \"New_Measurement\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"heavy_count\")\n",
    "    )\n",
    "    # TimeGroup별 총 차량 갯수 집계\n",
    "    total_df = (\n",
    "        copy_df.groupby([\"TimeGroup\", \"New_Measurement\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"total_count\")\n",
    "    )\n",
    "    heavy_rate_df = pd.merge(\n",
    "        heavy_df,\n",
    "        total_df,\n",
    "        on=[\"TimeGroup\", \"New_Measurement\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    heavy_rate_df[\"rate\"] = heavy_rate_df[\"heavy_count\"] / heavy_rate_df[\"total_count\"]\n",
    "    return heavy_rate_df\n",
    "\n",
    "\n",
    "# 동적 포화도\n",
    "def entry_saturation(original_df):\n",
    "    copy_df = original_df.copy()\n",
    "\n",
    "    # 실측용량 C(3차로 6600)\n",
    "    max_capacity = 6600\n",
    "    entry_saturation_df = (\n",
    "        copy_df.groupby([\"TimeGroup\", \"New_Measurement\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"entry_volume\")  # 차량 수를 entry_volume이라는 컬럼명으로\n",
    "    )\n",
    "\n",
    "    # 단위가 대/시 이기 때문에 현재 5분집계 * 12\n",
    "    entry_saturation_df[\"Phi_진입\"] = entry_saturation_df[\"entry_volume\"] * 12 / max_capacity\n",
    "    return entry_saturation_df\n",
    "\n",
    "# 램프 간섭 영향률\n",
    "def rfr_rate(original_df):\n",
    "    copy_df = original_df.copy()\n",
    "    copy_df[\"TimeGroup\"] = copy_df[\"TimeGroup\"].astype(str)\n",
    "    main_results=[]\n",
    "    for i, (before, after) in enumerate(zip(before_ramp, after_ramp)):\n",
    "        q_before = (copy_df[copy_df[\"New_Measurement\"] == before]\n",
    "                    .groupby(\"TimeGroup\")\n",
    "                    .size()\n",
    "                    .reset_index(name=\"q_before\"))\n",
    "\n",
    "        q_after = (copy_df[copy_df[\"New_Measurement\"] == after]\n",
    "                   .groupby(\"TimeGroup\")\n",
    "                   .size()\n",
    "                   .reset_index(name=\"q_after\"))\n",
    "        merged = q_before.merge(q_after, on=\"TimeGroup\", how=\"outer\").fillna(0)\n",
    "        merged[\"Qm\"] = (merged[\"q_before\"] + merged[\"q_after\"]) / 2\n",
    "        main_results.append(merged)\n",
    "\n",
    "    ramp_results = []\n",
    "    for input_, output_ in zip(input_ramp, output_ramp):\n",
    "        q_in = (copy_df[copy_df[\"New_Measurement\"] == input_]\n",
    "                .groupby(\"TimeGroup\").size().reset_index(name=\"q_in\"))\n",
    "        ramp_results.append(q_in)\n",
    "        q_out = (copy_df[copy_df[\"New_Measurement\"] == output_]\n",
    "                 .groupby(\"TimeGroup\").size().reset_index(name=\"q_out\"))\n",
    "        ramp_results.append(q_out)\n",
    "\n",
    "    rfr_list = []\n",
    "    for i in range(min(len(main_results), len(ramp_results))):\n",
    "        main_df = main_results[i]\n",
    "        ramp_df = ramp_results[i]\n",
    "\n",
    "        rfr_df = pd.merge(main_df, ramp_df, on=\"TimeGroup\", how=\"outer\").fillna(0)\n",
    "\n",
    "        if \"q_in\" in rfr_df.columns:\n",
    "            rfr_df[\"IR_in\"] = rfr_df[\"q_in\"] / rfr_df[\"Qm\"]\n",
    "        else:\n",
    "            rfr_df[\"IR_in\"] = 0\n",
    "\n",
    "        if \"q_out\" in rfr_df.columns:\n",
    "            rfr_df[\"IR_out\"] = rfr_df[\"q_out\"] / rfr_df[\"Qm\"]\n",
    "        else:\n",
    "            rfr_df[\"IR_out\"] = 0\n",
    "\n",
    "        rfr_df[\"RFR\"] = rfr_df[\"IR_in\"] + rfr_df[\"IR_out\"]\n",
    "\n",
    "        rfr_df[\"New_Measurement\"] = after_ramp[i]\n",
    "\n",
    "        rfr_list.append(rfr_df)\n",
    "\n",
    "    final_rfr_df = pd.concat(rfr_list, ignore_index=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 특정 검지기에만 RFR 반영\n",
    "    # -----------------------------\n",
    "    target_measurements = after_ramp   # RFR 적용 대상 검지기 번호\n",
    "    all_measurements = copy_df[\"New_Measurement\"].unique()\n",
    "\n",
    "    expanded_df_list = []\n",
    "\n",
    "    base_rfr_df = final_rfr_df.copy()\n",
    "\n",
    "    for m in all_measurements:\n",
    "        if m in target_measurements:\n",
    "            # 원래 53, 222 행만 남기기 위해 필터링\n",
    "            temp = base_rfr_df[base_rfr_df[\"New_Measurement\"] == m].copy()\n",
    "        else:\n",
    "            temp = base_rfr_df[[\"TimeGroup\"]].drop_duplicates().copy()\n",
    "            temp[\"New_Measurement\"] = m\n",
    "            temp[\"RFR\"] = 0\n",
    "\n",
    "        expanded_df_list.append(temp)\n",
    "\n",
    "    final_rfr_df = pd.concat(expanded_df_list, ignore_index=True)\n",
    "    final_rfr_df = final_rfr_df.sort_values(by=[\"TimeGroup\", \"New_Measurement\"]).reset_index(drop=True)\n",
    "    final_rfr_df = final_rfr_df[[\"TimeGroup\", \"New_Measurement\", \"RFR\"]]\n",
    "\n",
    "    return final_rfr_df\n",
    "\n",
    "# 진출 원활율\n",
    "def output_normality(original_df):\n",
    "    copy_df = original_df.copy()\n",
    "    entry_df = copy_df[copy_df[\"New_Measurement\"].isin(enter_line)][[\"VehNo\", \"t(Entry)\"]]\n",
    "\n",
    "    exit_df = copy_df[copy_df[\"New_Measurement\"] == after_ramp[1]][[\"VehNo\", \"t(Entry)\"]]\n",
    "\n",
    "    # 차량 번호로 그룹화 후 시간의 최솟값(중복제거)\n",
    "    entry_first = (\n",
    "        entry_df.groupby(\"VehNo\")[\"t(Entry)\"].min()\n",
    "        .reset_index()  # Series → DataFrame\n",
    "        .rename(columns={\"t(Entry)\": \"t_entry\"})\n",
    "    )\n",
    "\n",
    "    exit_first = (\n",
    "        exit_df.groupby(\"VehNo\")[\"t(Entry)\"].min()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"t(Entry)\": \"t_exit\"})\n",
    "    )\n",
    "\n",
    "    # 지연시간\n",
    "    merged = pd.merge(entry_first, exit_first, on=\"VehNo\", how=\"inner\")\n",
    "    merged[\"delay_sec\"] = merged[\"t_exit\"] - merged[\"t_entry\"]\n",
    "    merged = merged[merged[\"delay_sec\"] >= 0]  # 음수 제거\n",
    "\n",
    "    # 지연시간(중앙값) → lag_bins\n",
    "    if len(merged) and np.isfinite(np.nanmedian(merged[\"delay_sec\"])): # delay_sec의 값이 유효하면\n",
    "        lag_bins = int(round(np.nanmedian(merged[\"delay_sec\"]) / 300)) # 단위시간으로 나눴을 때의 중간값 => 3(900초) => 진입한 차량이 진출을 통과하는데 평균 900초가 걸림\n",
    "    else:\n",
    "        lag_bins = 0  # 데이터 부족 시 동시간 매칭\n",
    "\n",
    "    # TimeGroup별 진입/유출 카운트 집계\n",
    "    entry_count = (original_df[original_df[\"New_Measurement\"].isin(enter_line)]\n",
    "                .groupby(\"TimeGroup\").size().reset_index(name=\"Q_in\"))\n",
    "    exit_count  = (original_df[original_df[\"New_Measurement\"] == after_ramp[1]]\n",
    "                .groupby(\"TimeGroup\").size().reset_index(name=\"Q_out\"))\n",
    "\n",
    "    merged_counts = pd.merge(entry_count, exit_count, on=\"TimeGroup\", how=\"left\")\n",
    "\n",
    "    # Q_out을 지연 시간만큼 shift\n",
    "    merged_counts[\"Q_out_shift\"] = merged_counts[\"Q_out\"].shift(-lag_bins)\n",
    "\n",
    "    # F(outrate) 계산\n",
    "    merged_counts[\"F(outrate)\"] = (merged_counts[\"Q_out_shift\"] / merged_counts[\"Q_in\"]).fillna(0)\n",
    "\n",
    "    all_measurements = copy_df[\"New_Measurement\"].unique()\n",
    "    expanded_list = []\n",
    "\n",
    "    for m in all_measurements:\n",
    "        temp = merged_counts.copy()\n",
    "        temp[\"New_Measurement\"] = m\n",
    "        if m != after_ramp[1]:  # 222 이외의 검지기\n",
    "            temp[\"F(outrate)\"] = 0\n",
    "        expanded_list.append(temp)\n",
    "\n",
    "    final_df = pd.concat(expanded_list, ignore_index=True)\n",
    "    final_df = final_df.sort_values(by=[\"TimeGroup\", \"New_Measurement\"]).reset_index(drop=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def calculate_stvm(speed_df, density_df, heavy_df, entry_saturation_df, rfr_df, normality_df):\n",
    "\n",
    "    # TimeGroup 기준으로  Merge\n",
    "    merged_df = (\n",
    "        speed_df[[\"TimeGroup\", \"New_Measurement\", \"delta_V\"]]\n",
    "        .merge(density_df[[\"TimeGroup\", \"New_Measurement\", \"delta_K\"]], on=[\"TimeGroup\", \"New_Measurement\"])\n",
    "        .merge(heavy_df[[\"TimeGroup\", \"New_Measurement\", \"rate\"]], on=[\"TimeGroup\", \"New_Measurement\"])\n",
    "        .merge(entry_saturation_df[[\"TimeGroup\", \"New_Measurement\", \"Phi_진입\"]], on=[\"TimeGroup\", \"New_Measurement\"])\n",
    "        .merge(rfr_df[[\"TimeGroup\", \"New_Measurement\", \"RFR\"]], on=[\"TimeGroup\", \"New_Measurement\"])\n",
    "        .merge(normality_df[[\"TimeGroup\", \"New_Measurement\", \"F(outrate)\"]], on=[\"TimeGroup\", \"New_Measurement\"])\n",
    "    )\n",
    "\n",
    "    merged_df[\"STVM\"] = (\n",
    "        weights[\"w1\"] * merged_df[\"delta_V\"] +\n",
    "        weights[\"w2\"] * merged_df[\"delta_K\"] +\n",
    "        weights[\"w3\"] * merged_df[\"rate\"] +\n",
    "        weights[\"w4\"] * merged_df[\"Phi_진입\"] +\n",
    "        weights[\"w5\"] * merged_df[\"RFR\"] +\n",
    "        weights[\"w6\"] * merged_df[\"F(outrate)\"]\n",
    "    )\n",
    "    merged_df = modify_frame(merged_df)\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def calculate_z_score(stvm_df):\n",
    "    copy_df = stvm_df.copy()\n",
    "\n",
    "    # 평균\n",
    "    mean_stvm = copy_df[\"STVM\"].mean(skipna=True)\n",
    "\n",
    "    # 표준편차\n",
    "    std_stvm = copy_df[\"STVM\"].std(skipna=True)\n",
    "\n",
    "    # Z-Score 계산\n",
    "    copy_df[\"Z-Score\"] = (copy_df[\"STVM\"] - mean_stvm) / std_stvm\n",
    "    z_max = copy_df[\"Z-Score\"].max()\n",
    "    z_min = copy_df[\"Z-Score\"].min()\n",
    "\n",
    "    copy_df[\"환산점수\"] = copy_df[\"Z-Score\"].apply(lambda z : z_to_score(z, z_min, z_max))\n",
    "\n",
    "    stvm_df = pd.pivot(copy_df, index=\"TimeGroup\", columns= \"New_Measurement\", values=\"환산점수\")\n",
    "    return stvm_df\n",
    "\n",
    "def modify_frame(df):\n",
    "    modify_df = df.copy()\n",
    "\n",
    "    modify_df[\"StartTime\"] = modify_df[\"TimeGroup\"].str.split(\"~\").str[0].astype(int)\n",
    "    modify_df = modify_df[(modify_df[\"StartTime\"] >=1800) &(modify_df[\"StartTime\"] < 5400)]\n",
    "    modify_df = modify_df[~modify_df[\"New_Measurement\"].isin([280,998,999])]\n",
    "    return modify_df\n",
    "\n",
    "\n",
    "def variable_timegroup_avg(stvm_df):\n",
    "    copy_df = stvm_df.copy()\n",
    "    variable_time_df = copy_df.groupby(\"TimeGroup\")[[\"delta_V\", \"delta_K\", \"rate\", \"Phi_진입\", \"RFR\", \"F(outrate)\"]].mean()\n",
    "    return variable_time_df\n",
    "\n",
    "def variable_total_avg(variable_df):\n",
    "    variable_total_df = pd.DataFrame([variable_df.mean(numeric_only=True)])\n",
    "    return variable_total_df\n",
    "\n",
    "def speed_density_avg(density_df):\n",
    "    copy_df = density_df.copy()\n",
    "    avg_df = modify_frame(copy_df)\n",
    "    avg_df = pd.DataFrame([avg_df.mean(numeric_only=True)])\n",
    "    avg_df = avg_df[[\"V_mean\", \"K\"]]\n",
    "    return avg_df\n",
    "\n",
    "def pivot_table(df, value, preprocess=None):\n",
    "    copy_df = df.copy()\n",
    "    if preprocess :\n",
    "        copy_df = preprocess(copy_df)\n",
    "    return copy_df.pivot(index=\"TimeGroup\", columns=\"New_Measurement\", values=value)\n",
    "\n",
    "def weighted_avg_speed(original_df):\n",
    "    copy_df = original_df.copy()\n",
    "    # TimeGroup, New_Measurement별 그룹화 및 속도 평균\n",
    "    speed_mean_df = (\n",
    "        copy_df.groupby([\"TimeGroup\", \"New_Measurement\", \"Vehicle type\"])\n",
    "          .agg(V_mean=(\"v[km/h]\", \"mean\"), V_count=(\"v[km/h]\", \"count\"))\n",
    "          .reset_index()\n",
    "    )\n",
    "    speed_mean_df[\"std_group\"] = speed_mean_df.groupby([\"TimeGroup\", \"New_Measurement\"])[\"V_mean\"].transform(lambda s: s.std(ddof=0))\n",
    "    speed_mean_df[\"cv\"] = speed_mean_df[\"std_group\"] / speed_mean_df[\"V_mean\"]\n",
    "    speed_mean_df[\"w\"] = 1 / speed_mean_df[\"cv\"]\n",
    "    speed_mean_df[\"w*v\"] = speed_mean_df[\"w\"] * speed_mean_df[\"V_mean\"]\n",
    "\n",
    "    weighted_result = (\n",
    "        speed_mean_df.groupby([\"TimeGroup\",\"New_Measurement\"])\n",
    "          .apply(lambda g: g[\"w*v\"].sum() / g[\"w\"].sum())\n",
    "          .reset_index(name=\"Weighted_Avg_Speed\")\n",
    "    )\n",
    "\n",
    "    return weighted_result\n",
    "\n",
    "def save_to_excel(excel_df, folder_path, file_name, i):\n",
    "        excel_folder_path = os.path.join(folder_path, file_name)\n",
    "        os.makedirs(excel_folder_path, exist_ok=True)\n",
    "        excel_file_name = f\"{file_name}_{i+1}.xlsx\"\n",
    "        excel_file_path = os.path.join(excel_folder_path, excel_file_name)\n",
    "        excel_df.to_excel(excel_file_path, index=True)\n",
    "        print(f\"{excel_file_name} 생성 완료\")\n",
    "\n",
    "def z_to_score(z, z_min, z_max):\n",
    "    if 1.645 <= z <= z_max:\n",
    "        return 50 + ((95 + 5 * ((z - 1.645) / (z_max - 1.645))) * 0.5)\n",
    "    elif 1.282 <= z < 1.645:\n",
    "        return 50 + ((90 + 5 * ((z - 1.282) / (1.645 - 1.282))) * 0.5)\n",
    "    elif 1.038 <= z < 1.282:\n",
    "        return 50 + ((85 + 5 * ((z - 1.038) / (1.282 - 1.038))) * 0.5)\n",
    "    elif 0.842 <= z < 1.038:\n",
    "        return 50 + ((80 + 5 * ((z - 0.842) / (1.038 - 0.842))) * 0.5)\n",
    "    elif 0.676 <= z < 0.842:\n",
    "        return 50 + ((75 + 5 * ((z - 0.676) / (0.842 - 0.676))) * 0.5)\n",
    "    elif 0.526 <= z < 0.676:\n",
    "        return 50 + ((70 + 5 * ((z - 0.526) / (0.676 - 0.526))) * 0.5)\n",
    "    elif 0.387 <= z < 0.526:\n",
    "        return 50 + ((65 + 5 * ((z - 0.387) / (0.526 - 0.387))) * 0.5)\n",
    "    elif 0.255 <= z < 0.387:\n",
    "        return 50 + ((60 + 5 * ((z - 0.255) / (0.387 - 0.255))) * 0.5)\n",
    "    elif -0.255 <= z < 0.255:\n",
    "        return 50 + ((40 + 5 * ((z + 0.255) / (0.255 + 0.255))) * 0.5)\n",
    "    elif -0.387 <= z < -0.255:\n",
    "        return 50 + ((35 + 5 * ((z + 0.387) / (-0.255 + 0.387))) * 0.5)\n",
    "    elif -0.526 <= z < -0.387:\n",
    "        return 50 + ((30 + 5 * ((z + 0.526) / (-0.387 + 0.526))) * 0.5)\n",
    "    elif -0.676 <= z < -0.526:\n",
    "        return 50 + ((25 + 5 * ((z + 0.676) / (-0.676 + 0.842))) * 0.5)\n",
    "    elif -0.842 <= z < -0.676:\n",
    "        return 50 + ((20 + 5 * ((z + 0.842) / (-0.676 + 0.842))) * 0.5)\n",
    "    elif -1.038 <= z < -0.842:\n",
    "        return 50 + ((15 + 5 * ((z + 1.038) / (-0.842 + 1.038))) * 0.5)\n",
    "    elif -1.282 <= z < -1.038:\n",
    "        return 50 + ((10 + 5 * ((z + 1.282) / (-1.038 + 1.282))) * 0.5)\n",
    "    elif -1.645 <= z < -1.282:\n",
    "        return 50 + ((5 + 5 * ((z + 1.645) / (-1.282 + 1.645))) * 0.5)\n",
    "    elif z_min <= z < -1.645:\n",
    "        return 50 + ((0 + 5 * ((z + z_min) / (-1.645 + z_min))) * 0.5)\n",
    "    else:\n",
    "        return np.nan\n",
    "###################################################################################################################\n",
    "\n",
    "folder_path = path\n",
    "mer_list = sorted(\n",
    "    [file for file in os.listdir(folder_path) if file.endswith(\".mer\")],\n",
    "    key=lambda x: int(re.search(r\"(\\d+)(?=\\.mer$)\", x).group()) if re.search(r\"(\\d+)(?=\\.mer$)\", x) else 0\n",
    ")\n",
    "\n",
    "grouped_df = pd.DataFrame()\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(mer_list)):\n",
    "    mer_file = mer_list[i]\n",
    "    print(\"작업파일 : \", mer_file)\n",
    "    with open(os.path.join(folder_path, mer_file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "            lines = file.readlines()\n",
    "            # 데이터가 시작하는 인덱스 찾기\n",
    "            data_start_idx = None\n",
    "\n",
    "            for j, line in enumerate(lines):\n",
    "                if \"Measurem.\" in line:  # 컬럼명이 포함된 행 찾기\n",
    "                    data_start_idx = j\n",
    "                    break\n",
    "\n",
    "            # 데이터프레임 생성\n",
    "            if data_start_idx is not None:\n",
    "\n",
    "                # 컬럼명 추출 및 공백 제거\n",
    "                columns = [col.strip() for col in lines[data_start_idx].strip().split(\";\")]\n",
    "\n",
    "                # 데이터 부분 추출 및 가공\n",
    "                data_lines = lines[data_start_idx + 1:]  # 컬럼명 제외, 데이터 부분\n",
    "                data = [line.strip().split(\";\") for line in data_lines if line.strip()]\n",
    "\n",
    "                # 데이터프레임 생성\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "                # 컬럼 내부 데이터 정수형 변환\n",
    "                df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "                original_df = df[(df[\"t(Entry)\"] != -1.00)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "                #불필요 컬럼 제거\n",
    "                original_df.drop(columns=[\"b[m/s2]\", \"tQueue\", \"Occ\", \"Pers\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "                original_df[\"New_Measurement\"] = original_df[\"Measurem.\"] % 1000\n",
    "\n",
    "                bins = np.arange(start_interval, end_interval+1, 300)\n",
    "                labels = [f\"{start}~{start+300}\" for start in bins[:-1]]  # 구간 라벨링\n",
    "\n",
    "                # 구간 나누기 및 컬럼 추가\n",
    "                original_df[\"TimeGroup\"] = pd.cut(original_df[\"t(Entry)\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "                # 속도변화율\n",
    "                speed_df = speed_mean(original_df)\n",
    "\n",
    "                # 밀도변화율\n",
    "                density_df = density_mean(speed_df)\n",
    "\n",
    "                # 중차량 혼입률\n",
    "                heavy_df = heavy_rate(original_df)\n",
    "\n",
    "                # 동적 포화도\n",
    "                entry_saturation_df = entry_saturation(original_df)\n",
    "\n",
    "                # 램프 간섭 영향률\n",
    "                rfr_df = rfr_rate(original_df)\n",
    "\n",
    "                # 진출 원활율\n",
    "                normality_df = output_normality(original_df)\n",
    "\n",
    "                # STVM 계산\n",
    "                stvm_df = calculate_stvm(speed_df, density_df, heavy_df, entry_saturation_df, rfr_df, normality_df)\n",
    "                save_to_excel(stvm_df, folder_path, \"STVM\", i)\n",
    "\n",
    "                # Z-Score 계산\n",
    "                z_score_df = calculate_z_score(stvm_df)\n",
    "                #save_to_excel(z_score_df, folder_path, \"환산점수\", i)\n",
    "\n",
    "                # STVM 피봇\n",
    "                #stvm_pivot_df = pivot_table(stvm_df, \"STVM\")\n",
    "                #save_to_excel(stvm_pivot_df, folder_path, \"STVM\", i)\n",
    "\n",
    "                # 속도값 피봇\n",
    "                #speed_pivot_df = pivot_table(speed_df, \"V_mean\", preprocess=modify_frame)\n",
    "                #save_to_excel(speed_pivot_df, folder_path, \"속도값\", i)\n",
    "\n",
    "                # 메모리 정리\n",
    "                #del df, original_df, speed_df, density_df, heavy_df, entry_saturation_df, rfr_df, normality_df, stvm_df, z_score_df\n",
    "                gc.collect()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업파일 :  ToyNetwork_진입,진출램프_600.mer\n",
      "STVM_1.xlsx 생성 완료\n",
      "작업파일 :  ToyNetwork_진입,진출램프_1000.mer\n",
      "STVM_2.xlsx 생성 완료\n",
      "작업파일 :  ToyNetwork_진입,진출램프_1350.mer\n",
      "STVM_3.xlsx 생성 완료\n",
      "작업파일 :  ToyNetwork_진입,진출램프_1750.mer\n",
      "STVM_4.xlsx 생성 완료\n",
      "작업파일 :  ToyNetwork_진입,진출램프_2200.mer\n",
      "STVM_5.xlsx 생성 완료\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5475cbc1e63235bb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
