{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T05:52:56.055258Z",
     "start_time": "2025-03-17T05:52:14.525662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\"\"\"results 파일에서 엑셀 변환\"\"\"\n",
    "# ✅ Excel 파일이 있는 폴더 경로\n",
    "folder_path = r\"C:\\VISSIM_Workspace\\network_test\"\n",
    "file_path = r\"C:\\VISSIM_Workspace\\network_test\\network01.inpx\"\n",
    "\n",
    "from_time = 1800\n",
    "siml_count = 10\n",
    "\n",
    "# XML 파일 파싱\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "for elem in root.iter(\"dataColl\"):\n",
    "    interval_value = int(elem.get(\"interval\"))  # \"interval\" 속성 값 가져오기\n",
    "\n",
    "results_path = folder_path + \"\\\\\" + \"network01.results\"\n",
    "results_files = sorted([f for f in os.listdir(results_path) if f.endswith(\".db\")], key=lambda x: int(x.split(\".\")[0]))\n",
    "#print(results_files)\n",
    "\n",
    "for results_file in results_files:\n",
    "    # .db파일 데이터의 평균 도출\n",
    "    db_path = os.path.join(results_path, results_file)\n",
    "    # 데이터베이스 연결\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 특정 테이블의 데이터 조회\n",
    "    table_name = \"DATACOLLECTIONMEASUREMENT_EvaluationTimeIntervalClass\"\n",
    "    query = f\"SELECT * FROM {table_name};\"  # 전체 데이터 조회\n",
    "\n",
    "    # 데이터 읽기\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    # TIMEINT 변환\n",
    "    df[\"ARG_TIMEINTERVAL\"] = from_time + df[\"ARG_TIMEINTERVAL\"].astype(int) * interval_value   # 변환 시작점 보정\n",
    "\n",
    "    # OCCUPRATE 보정\n",
    "    df[\"OCCUPRATE\"] = df[\"OCCUPRATE\"].astype(float)*100\n",
    "    df[\"OCCUPRATE\"] = df[\"OCCUPRATE\"].apply(lambda x: f\"{x:.2f}\")  # 항상 소수점 둘째 자리까지 유지\n",
    "    df = df.round(2)\n",
    "    df[\"OCCUPRATE\"] = df[\"OCCUPRATE\"].astype(str) + \"%\"\n",
    "\n",
    "    # SIMRUN 설정\n",
    "    df[\"SIMRUN\"] =siml_count\n",
    "    df[\"OBJECT_ID\"] = df[\"OBJECT_ID\"].astype(int)\n",
    "    # 컬럼명 변경\n",
    "    df.rename(columns={\n",
    "        \"ARG_TIMEINTERVAL\": \"TIMEINT\",\n",
    "        \"OBJECT_ID\": \"DATACOLLECTIONMEASUREMENT\",\n",
    "        \"ACCELERATION\" : \"ACCELERATION(ALL)\",\n",
    "        \"DIST\" : \"DIST(ALL)\",\n",
    "        \"LENGTH\" : \"LENGTH(ALL)\",\n",
    "        \"VEHS\" : \"VEHS(ALL)\",\n",
    "        \"PERS\" : \"PERS(ALL)\",\n",
    "        \"QUEUEDELAY\" : \"QUEUEDELAY(ALL)\",\n",
    "        \"SPEEDAVGARITH\" : \"SPEEDAVGARITH(ALL)\",\n",
    "        \"SPEEDAVGHARM\" : \"SPEEDAVGHARM(ALL)\",\n",
    "        \"OCCUPRATE\" : \"OCCUPRATE(ALL)\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # 순서 재정의\n",
    "    df = df[[\"SIMRUN\", \"TIMEINT\", \"DATACOLLECTIONMEASUREMENT\", \"ACCELERATION(ALL)\", \"DIST(ALL)\",\n",
    "             \"LENGTH(ALL)\", \"VEHS(ALL)\", \"PERS(ALL)\", \"QUEUEDELAY(ALL)\", \"SPEEDAVGARITH(ALL)\", \"SPEEDAVGHARM(ALL)\", \"OCCUPRATE(ALL)\"]]\n",
    "\n",
    "    excel_dir  = os.path.join(folder_path, \"network02_output\")\n",
    "    if not os.path.exists(excel_dir):\n",
    "        os.makedirs(excel_dir)\n",
    "    last_file = xlsx_files = sorted([f for f in os.listdir(excel_dir) if f.endswith(\".xlsx\")], key=lambda x: int(x.split(\"_\")[0]) if x.split(\"_\")[0].isdigit() else 0)\n",
    "\n",
    "    if not xlsx_files:\n",
    "        last_file = 1\n",
    "    else:\n",
    "        last_file = int(xlsx_files[-1].split(\"_\")[0]) + 1  # 가장 마지막 파일 번호 + 1\n",
    "    excel_path = os.path.join(excel_dir, f\"{last_file}_output.xlsx\")\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    print(f\"생성파일: {excel_path}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.db', '2.db', '3.db', '4.db', '5.db', '6.db', '7.db', '8.db', '9.db', '10.db', '11.db', '12.db', '13.db', '14.db', '15.db', '16.db', '17.db', '18.db', '19.db', '20.db', '21.db', '22.db', '23.db', '24.db', '25.db', '26.db', '27.db', '28.db', '29.db', '30.db', '31.db', '32.db', '33.db', '34.db', '35.db', '36.db', '37.db', '38.db', '39.db', '40.db', '41.db', '42.db', '43.db', '44.db', '45.db', '46.db', '47.db', '48.db']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7155b37dc7471574"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9812b555c2bab633",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
